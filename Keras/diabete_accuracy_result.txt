#with same training / test sets  / epochs : 150 / batchs : 10
=================================================
m.add(Dense(8, input_dim=8, activation = 'relu'))
m.add(Dense(1, activation="sigmoid"))

-> acc : 70.18%
=================================================
m.add(Dense(12, input_dim=8, activation = 'relu'))
m.add(Dense(1, activation="sigmoid"))

-> acc : 65.36%
=================================================
m.add(Dense(1, input_dim=8, activation = 'relu'))
m.add(Dense(1, activation="sigmoid"))

-> acc : 65.10%
=================================================
m.add(Dense(8, input_dim=8, activation = 'relu'))
m.add(Dense(8, activation = 'relu'))
m.add(Dense(1, activation="sigmoid"))

-> acc : 75.00%
=================================================
m.add(Dense(16, input_dim=8, activation = 'relu'))
m.add(Dropout(16))
m.add(Dense(16, activation = 'relu'))
m.add(Dense(1, activation="sigmoid"))

-> acc : 75.13%
=================================================
-----------------------------------------------

switched to batch_size = 128 -> way faster
=================================================
m.add(Dense(16, input_dim=8, activation = 'relu'))
m.add(Dropout(16))
m.add(Dense(16, activation = 'relu'))
m.add(Dense(1, activation="sigmoid"))

-> acc : 76.17%
=================================================
m.add(Dense(16, input_dim=8, activation = 'relu'))
m.add(Dropout(16))
for i in range(8):
  m.add(Dense(16, activation = 'relu'))
m.add(Dense(1, activation="sigmoid"))

-> acc : 85.68% #best so far
=================================================
m.add(Dense(16, input_dim=8, activation = 'relu'))
m.add(Dropout(16))
for i in range(16):
  m.add(Dense(16, activation = 'relu'))
m.add(Dense(1, activation="sigmoid"))

-> acc : 82.94%
=================================================
#relu seems the best activation fonction so far, tried with sigmoids in dense layers but we loose performances


m.add(Dense(8, input_dim=8, activation = 'relu'))
m.add(Dropout(8))
for i in range(8):
  m.add(Dense(8, activation = 'relu'))
m.add(Dropout(8))
m.add(Dense(1, activation="sigmoid"))

-> acc : 79.69%
=================================================





###### 300 epochs
m.add(Dense(16, input_dim=8, activation = 'relu'))
m.add(Dropout(16))
for i in range(8):
  m.add(Dense(16, activation = 'relu'))
m.add(Dense(1, activation="sigmoid"))

-> acc : 92.06% but maybe biased


##### 1000 epochs : 96.48% acc

m = Sequential()
m.add(Dense(16, input_dim=8, activation = 'relu'))
m.add(Dropout(16))
for i in range(8):
  m.add(Dense(16, activation = 'relu'))
  m.add(Dropout(16))
m.add(Dense(1, activation="sigmoid"))
m.summary()

##### 10'000 epochs : 99.74%

another try with 100.00% accuracy

#######################################################################

now with training set / test set

576 first samples for training, last 192 for test

epochs = 1000, batch_size = 576

m.add(Dense(16, input_dim=8, activation = 'relu'))
m.add(Dropout(16))
for i in range(4):
  m.add(Dense(16, activation = 'relu'))
  m.add(Dropout(16))
m.add(Dense(1, activation="sigmoid"))

acc : 70.31%


m.add(Dense(16, input_dim=8, activation = 'relu'))
for i in range(4):
  m.add(Dense(16, activation = 'relu'))
m.add(Dense(1, activation="sigmoid"))

acc : 71.35%

m.add(Dense(8, input_dim=8, activation = 'relu'))
for i in range(4):
  m.add(Dense(8, activation = 'relu'))
m.add(Dense(1, activation="sigmoid"))

acc : 66.15%



m.add(Dense(8, input_dim=8, activation = 'relu'))
for i in range(16):
    m.add(Dense(8, activation = 'relu'))
    m.add(Dropout(8))
m.add(Dense(1, activation="sigmoid"))

Training scores :
acc: 77.78%
192/192 [==============================] - ETA: 0s
Testing scores :
acc: 59.38%



m.add(Dense(16, input_dim=8, activation = 'relu'))
m.add(Dropout(16))
for i in range(8):
  m.add(Dense(16, activation = 'relu'))
  m.add(Dropout(16))
m.add(Dense(1, activation="sigmoid"))

epochs = 8000, batch_size = 128

576/576 [==============================] - ETA: 0s
Training scores :
acc: 100.00%
192/192 [==============================] - ETA: 0s
Testing scores :
acc: 69.79%

same with batch_size = 576 :

576/576 [==============================] - ETA: 0s
Training scores :
acc: 99.83%
192/192 [==============================] - ETA: 0s
Testing scores :
acc: 61.98%


m.add(Dense(8, input_dim=8, activation = 'relu'))
m.add(Dropout(8))
m.add(Dense(1, activation="sigmoid"))
m.fit(X_train, Y_train, epochs=8000, batch_size=128, verbose=0)

Training scores :
acc: 78.47%
192/192 [==============================] - ETA: 0s
Testing scores :
acc: 73.44%





m.add(Dense(8, input_dim=8, activation = 'relu'))
m.add(Dropout(8))
m.add(Dense(8, input_dim=8, activation = 'relu'))
m.add(Dropout(8))
m.add(Dense(8, input_dim=8, activation = 'relu'))
m.add(Dropout(8))

m.fit(X_train, Y_train, epochs=3000, batch_size=128, verbose=0)

576/576 [==============================] - ETA: 0s
Training scores :
acc: 81.25%
192/192 [==============================] - ETA: 0s
Testing scores :
acc: 75.52% #mvp


m.fit(X_train, Y_train, epochs=50000, batch_size=128, verbose=0)  #overkill lol
576/576 [==============================] - ETA: 0s
Training scores :
acc: 80.56%
192/192 [==============================] - ETA: 0s
Testing scores :
acc: 71.88%
